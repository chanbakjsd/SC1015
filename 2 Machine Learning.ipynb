{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like earlier, we\"ll be reading the `cleaned.csv` file and importing all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"cleaned.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Machine Learning\n",
    "\n",
    "Before we go too crazy, we will start by doing regressions based on the numerical figures available in the dataset.\n",
    "\n",
    "We start by retrieving the numerical values, taking care to drop the incremented ID and making owners logarithmic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achievements</th>\n",
       "      <th>average_playtime</th>\n",
       "      <th>median_playtime</th>\n",
       "      <th>owners</th>\n",
       "      <th>price</th>\n",
       "      <th>platforms_windows</th>\n",
       "      <th>platforms_mac</th>\n",
       "      <th>platforms_linux</th>\n",
       "      <th>categories_Multi-player</th>\n",
       "      <th>categories_Online Multi-Player</th>\n",
       "      <th>...</th>\n",
       "      <th>genres_Software Training</th>\n",
       "      <th>genres_Sexual Content</th>\n",
       "      <th>genres_Audio Production</th>\n",
       "      <th>genres_Game Development</th>\n",
       "      <th>genres_Photo Editing</th>\n",
       "      <th>genres_Accounting</th>\n",
       "      <th>genres_Documentary</th>\n",
       "      <th>genres_Tutorial</th>\n",
       "      <th>age</th>\n",
       "      <th>positive_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17612</td>\n",
       "      <td>317</td>\n",
       "      <td>7.176091</td>\n",
       "      <td>7.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.973888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>62</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7580</td>\n",
       "      <td>0.839787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>34</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6089</td>\n",
       "      <td>0.895648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>184</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6788</td>\n",
       "      <td>0.826623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "      <td>415</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7366</td>\n",
       "      <td>0.947996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.544068</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0.776923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15040 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       achievements  average_playtime  median_playtime    owners  price   \n",
       "0                 0             17612              317  7.176091   7.19  \\\n",
       "1                 0               277               62  6.875061   3.99   \n",
       "2                 0               187               34  6.875061   3.99   \n",
       "3                 0               258              184  6.875061   3.99   \n",
       "4                 0               624              415  6.875061   3.99   \n",
       "...             ...               ...              ...       ...    ...   \n",
       "15035            12                 0                0  4.000000   7.19   \n",
       "15036             7                 0                0  4.000000   0.00   \n",
       "15037             0                 0                0  4.544068   0.00   \n",
       "15038            23                 0                0  4.000000   6.10   \n",
       "15039             0                 0                0  4.000000   0.79   \n",
       "\n",
       "       platforms_windows  platforms_mac  platforms_linux   \n",
       "0                      1              1                1  \\\n",
       "1                      1              1                1   \n",
       "2                      1              1                1   \n",
       "3                      1              1                1   \n",
       "4                      1              1                1   \n",
       "...                  ...            ...              ...   \n",
       "15035                  1              0                0   \n",
       "15036                  1              0                0   \n",
       "15037                  1              0                0   \n",
       "15038                  1              0                0   \n",
       "15039                  1              0                0   \n",
       "\n",
       "       categories_Multi-player  categories_Online Multi-Player  ...   \n",
       "0                            1                               1  ...  \\\n",
       "1                            1                               1  ...   \n",
       "2                            1                               0  ...   \n",
       "3                            1                               1  ...   \n",
       "4                            1                               0  ...   \n",
       "...                        ...                             ...  ...   \n",
       "15035                        0                               0  ...   \n",
       "15036                        0                               0  ...   \n",
       "15037                        0                               0  ...   \n",
       "15038                        0                               0  ...   \n",
       "15039                        0                               0  ...   \n",
       "\n",
       "       genres_Software Training  genres_Sexual Content   \n",
       "0                             0                      0  \\\n",
       "1                             0                      0   \n",
       "2                             0                      0   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "...                         ...                    ...   \n",
       "15035                         0                      0   \n",
       "15036                         0                      0   \n",
       "15037                         0                      0   \n",
       "15038                         0                      0   \n",
       "15039                         0                      0   \n",
       "\n",
       "       genres_Audio Production  genres_Game Development  genres_Photo Editing   \n",
       "0                            0                        0                     0  \\\n",
       "1                            0                        0                     0   \n",
       "2                            0                        0                     0   \n",
       "3                            0                        0                     0   \n",
       "4                            0                        0                     0   \n",
       "...                        ...                      ...                   ...   \n",
       "15035                        0                        0                     0   \n",
       "15036                        0                        0                     0   \n",
       "15037                        0                        0                     0   \n",
       "15038                        0                        0                     0   \n",
       "15039                        0                        0                     0   \n",
       "\n",
       "       genres_Accounting  genres_Documentary  genres_Tutorial   age   \n",
       "0                      0                   0                0  7000  \\\n",
       "1                      0                   0                0  7580   \n",
       "2                      0                   0                0  6089   \n",
       "3                      0                   0                0  6788   \n",
       "4                      0                   0                0  7366   \n",
       "...                  ...                 ...              ...   ...   \n",
       "15035                  0                   0                0   260   \n",
       "15036                  0                   0                0   260   \n",
       "15037                  0                   0                0   265   \n",
       "15038                  0                   0                0   257   \n",
       "15039                  0                   0                0   259   \n",
       "\n",
       "       positive_ratio  \n",
       "0            0.973888  \n",
       "1            0.839787  \n",
       "2            0.895648  \n",
       "3            0.826623  \n",
       "4            0.947996  \n",
       "...               ...  \n",
       "15035        0.714286  \n",
       "15036        0.846939  \n",
       "15037        0.776923  \n",
       "15038        0.733333  \n",
       "15039        0.781250  \n",
       "\n",
       "[15040 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "data_num = data.select_dtypes(include=np.number)\n",
    "data_num[\"owners\"] = np.log10(data_num[\"owners\"])\n",
    "data_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the dataset into train/test like usual. Random state values have been set to make the results deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape: (11280, 67)\n",
      "Test input shape: (3760, 67)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_x = data_num.drop(columns=\"price\")\n",
    "data_y = data_num[[\"price\"]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1234567)\n",
    "print(\"Train input shape:\", x_train.shape)\n",
    "print(\"Test input shape:\", x_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we throw different regressors at the job and observe how well they perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dummy Regressor (Baseline) ===\n",
      "Score: -0.00 (p-value 0.714)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Linear Regression ===\n",
      "Score: -188456601492828258304.00 (p-value 0.095)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Decision Tree ===\n",
      "Score: -0.04 (p-value 0.048)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Random Forest ===\n",
      "Score: 0.46 (p-value 0.091)\n",
      "               Best: 0.091\n",
      "\n",
      "=== Boosting Regressor ===\n",
      "Score: 0.47 (p-value 0.167)\n",
      "               Best: 0.167\n",
      "\n",
      "=== Multi-layer Perceptron ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanbakjsd/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.26 (p-value 0.250)\n",
      "               Best: 0.250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "y_train_arr = y_train_scaled.ravel()\n",
    "y_test_arr = y_test_scaled.ravel()\n",
    "\n",
    "def evaluate(name, model, perm=20):\n",
    "    print(\"===\", name, \"===\")\n",
    "    score = permutation_test_score(model, x_train_scaled, y_train_arr, n_permutations=perm)\n",
    "    print(f\"Score: {score[0]:.2f} (p-value {score[2]:.3f})\")\n",
    "    print(f\"               Best: {1/(perm+1):.3f}\")\n",
    "    print()\n",
    "\n",
    "print()\n",
    "\n",
    "evaluate(\"Dummy Regressor (Baseline)\", DummyRegressor())\n",
    "evaluate(\"Linear Regression\", LinearRegression())\n",
    "evaluate(\"Decision Tree\", DecisionTreeRegressor(random_state=0))\n",
    "evaluate(\"Random Forest\", RandomForestRegressor(random_state=0, max_samples=0.5), perm=10)\n",
    "evaluate(\"Boosting Regressor\", HistGradientBoostingRegressor(random_state=0), perm=5)\n",
    "evaluate(\"Multi-layer Perceptron\", MLPRegressor(random_state=0, solver=\"adam\"), perm=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As a baseline, a dummy regressor and linear regression was added.\n",
    "\n",
    "2. As expected, the decision tree immediately overfitted with a negative R^2 score for the test dataset. Random forest, the cousin to decision tree that is less prone to overfitting, performed somewhat decently in test with R^2 of `0.24`.\n",
    "\n",
    "3. The boosting regressor performed better than random forest with a slightly higher R^2.\n",
    "\n",
    "Let\"s see if we can do better with a different set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters were:\n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "Score:  0.5151563296318206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "parameter_space = {\n",
    "    \"hidden_layer_sizes\": [(50,), (50,50), (25,), (25,25,)], # Have some smaller sizes as we overfitted earlier.\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.05],\n",
    "    \"learning_rate\": [\"constant\",\"adaptive\"],\n",
    "}\n",
    "\n",
    "# Ignore ConvergenceWarning to avoid spamming the output.\n",
    "# SGD does not converge with 100 iterations in this dataset.\n",
    "warnings.filterwarnings(action=\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "mlp = MLPRegressor(random_state=0, max_iter=100)\n",
    "gridSearch = GridSearchCV(mlp, parameter_space, cv=5)\n",
    "gridSearch.fit(x_train_scaled, y_train_arr)\n",
    "\n",
    "train_pred = gridSearch.predict(x_train_scaled)\n",
    "test_pred = gridSearch.predict(x_test_scaled)\n",
    "print(f\"The best parameters were:\\n{gridSearch.best_params_}\")\n",
    "print(\"Score: \", r2_score(y_train_scaled, train_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have `{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,50), 'learning_rate': 'constant', 'solver': 'sgd'}` as the best parameters for the solver. Let's run it with extra iterations to make sure it performs the best it can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP Fine Tuned ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanbakjsd/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.27 (p-value 0.333)\n",
      "               Best: 0.333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.resetwarnings()\n",
    "mlp = MLPRegressor(random_state=0, activation=\"relu\", solver=\"sgd\", learning_rate=\"constant\", alpha=0.05, hidden_layer_sizes=(50,50), max_iter=1000)\n",
    "evaluate(\"MLP Fine Tuned\", mlp, perm=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, overfitting is a major issue in this case and even though R^2 increased for train, it decreased for test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "\n",
    "Thusfar, we have been ignoring a variable that we have kept when we cleaned the data: Detailed description.\n",
    "\n",
    "Let's try to vectorize it using `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15040, 54806)\n",
      "['00' '000' '0000' ... 'zyorzia' 'zypheria' 'zytron']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "transformed = vectorizer.fit_transform(data[\"detailed_description\"])\n",
    "print(transformed.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Maybe not that. The data definitely needs a lot more cleaning if it needs 54806 tokens.\n",
    "\n",
    "Let's take a page out of GPT-3 (and GPT-2), attempt byte pair encoding and see how it works out. As a bonus, we replace all the game titles with a special NAME token, just to make it more generalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['multiplayer', 'experience', 'characters', 'different', 'adventure', 'character', 'challenge', '<|name|>', 'features', 'gameplay', 'challeng', 'discover', 'complete', 'yourself', 'powerful', 'platform', 'difficul', 'original', 'through', 'players', 'enemies', 'control', 'weapons', 'explore', 'friends', 'against', 'collect', 'develop', 'special', 'puzzles', 'between', 'support', 'environ', 'survive', 'journey', 'destroy', 'player', 'experi', 'differ', 'contro', 'advent', 'friend', 'unique', 'ations', 'battle', 'action', 'levels', 'system', 'comple', 'develo', 'myster', 'acters', 'strate', 'create', \"you'll\", 'combat', 'skills', 'around', 'design', 'choose', 'become', 'person', 'before', 'unlock', 'attack', 'people', 'custom', 'origin', 'online', 'master', 'puzzle', 'ground', 'search', 'ation', 'world', 'their', 'level', 'every', 'thing', 'other', 'there', 'story', 'power', 'ments', 'where', 'which', 'build', 'fight', 'chall', 'games', 'inter', 'survi', 'cover', 'explo', 'again', 'ition', 'about', 'multi', 'ities', 'skill', 'first', 'inclu', 'class', 'while', 'based', 'track', 'ating', 'after', 'acter', 'ction', 'space', 'speci', 'under', 'uring', 'great', 'start', 'human', 'sound', 'these', 'using', 'allow', 'secre', 'steam', 'creat', 'enemy', 'iting', 'music', 'fully', 'items', 'gener', 'style', 'graph', 'place', 'envir', 'enjoy', 'sters', 'quest', 'order', 'incre', 'right', 'ative', 'stand', 'modes', 'learn', 'your', 'with', 'game', 'play', 'will', 'ther', 'that', 'from', 'ight', 'this', 'ment', 'ough', 'have', 'ever', 'ound', 'more', 'comp', 'able', 'ions', 'time', 'cont', 'ures', 'tory', 'king', 'feat', 'diff', 'ence', '.\\n- ', 'real', 'them', 'into', 'ical', 'char', 'over', 'peri', 'each', 'some', 'they', 'enem', 'batt', 'find', 'come', 'ated', 'expl', 'like', 'chan', \"you'\", 'gain', 'what', 'form', 'only', 'ting', 'weap', 'take', 'make', 'land', 'mode', 'comb', 'also', 'ning', 'most', 'back', 'puzz', 'life', 'when', 'just', 'ents', 'fore', 'syst', 'lect', 'self', 'lock', 'line', 'choo', 'plan', 'port', 'need', \"it's\", 'work', 'reat', 'even', 'help', 'turn', 'ving', 'ards', 'than', 'ould', 'ance', 'vari', 'high', 'ally', 'many', 'pers', 'vers', 'ship', 'miss', 'velo', 'ious', 'team', 'comm', 'cess', 'myst', 'tive', 'abil', 'down', 'ster', 'less', 'hero', 'ress', 'lear', 'part', 'coun', 'must', 'ding', 'ings', 'been', 'free', 'read', 'lead', 'tain', 'full', 'shoo', 'arch', 'item', 'want', 'well', 'year', 'hand', 'dark', 'best', 'enge', 'long', '!\\n- ', 'then', 'dest', 'sive', 'face', 'icul', 'ross', 'very', 'ople', 'sing', 'orig', 'ense', 'main', \"on't\", 'tion', 'ness', 'city', 'hard', 'here', 'ways', 'fast', 'keep', '... ', 'side', 'ines', 'plat', 'dead', 'mple', 'ween', 'stru', 'know', 'core', 'llow', 'jour', 'save', 'move', 'open', 'tech', 'fect', 'such', 'ates', 'head', 'good', 'ouse', 'kill', 'the', 'and', 'ing', 'you', 'ion', 'ent', 'for', 'ers', 'ver', 'ill', 'all', 'are', 'ter', 'wor', 'ure', 'igh', 'con', '\\n- ', 'ate', 'can', 'rom', 'ies', 'end', 'est', 'cre', 'tor', 'oun', 'act', 'out', 'one', 'ave', 'ack', 'man', 'com', 'our', 'new', 'per', 'ach', 'ous', 'ind', 'ard', 'ess', 'pro', 'her', 'ful', 'ast', 'ity', 'des', 'own', 'vel', 'but', 'ace', 'res', ' - ', 'att', 'art', 'ant', 'ust', 'ine', 'way', 'thr', 'his', 'str', 'les', 'has', 'der', 'yst', 'ive', 'not', 'ere', 'its', 'ass', 'ild', 'ort', 'who', 'get', 'use', 'adv', 'tra', 'ons', 'ire', 'ong', 'ich', 'ear', 'mes', 'sur', 'pow', 'uni', 'mul', 'spe', 'dis', 'now', 'ist', 'col', 'ick', 'ics', 'ble', 'war', 'ree', 'ile', 'ual', 'eng', 'que', 'ces', 'gra', 'ari', 'ish', 'off', 'any', 'ign', 'age', 'bas', 'min', 'set', 'fri', 'sel', 'ans', 'clu', 'pre', 'ste', 'mon', 'ice', 'sup', 'ves', 'tur', 'ark', 'was', 'ins', 'hel', 'led', 'ens', 'int', 'mis', 'how', 'fir', 'ser', 'ite', 'ary', 'add', 'ath', 'imp', 'she', 'mag', 'ang', 'gen', 'cap', 'mat', 'ase', 'cus', 'ren', 'fin', 'arm', 'day', 'val', 'bet', 'tru', 'row', 'ber', 'vir', 'try', 'sol', 'vis', 'fun', 'cor', 'sto', 'cra', 'ash', 'pos', 'ple', 'cal', 'air', 'tom', 'tow', 'ced', 'sty', 'car', 'med', 'als', 'inv', 'kes', 'ail', 'see', 'cur', 'hor', 'run', 'two', 'app', 'may', 'cts', 'asy', 'hun', 'def', 'mus', 'dra', 'tal', 'ran', 'ise', 'him', 'ors', 'ide', 'mem', 'mer', 'ele', 'dre', 'joy', 'par', 'let', 'ars', 'ved', 'den', 'cho', 'roy', 'old', 'wat', 'tri', 'stu', 'key', 'tim', 'lit', 'ven', 'fam', 'ney', 'beg', 'win', 'dri', 'dep', 'tre', 'bre', 'ily', 'gir', 'ial', 'top', 'tho', 'red', 'leg', 'lim', 'ali', 'tle', 'fac', 'th', 'in', 'an', 'er', 'ou', 're', 'on', ', ', 'en', 'to', 'es', 'at', 'or', 'al', 'st', 'ar', 'is', 'le', 'of', '. ', 'it', 'me', 'ac', 'ed', 'as', 'ic', 'il', 've', 'ro', '.\\n', 'se', 'pl', 'ch', 'de', 'ay', 'co', 'ga', 'un', 'be', 'wi', '- ', 'ow', 'ly', 'ad', 'ig', 'wh', 'mo', 'ge', 'ul', 'lo', 'ra', 'ne', 'ir', 'ti', 'ma', 'ur', 'ld', 'ke', 'sh', 'ts', 'ri', 'ex', 'mp', 'so', 'ab', 'ce', 'fe', 'li', 'di', 'ap', 'we', 'us', 'up', 'sp', 'ut', 'am', \"'s\", 'qu', 'em', 'no', 'tr', 'te', 'ct', 'he', 'ta', 'll', 'si', 'op', 'bo', 'by', 'gh', 'vi', 'go', 'cl', 'do', '!\\n', 'po', 'ci', 'oo', 'ff', ': ', 'pe', 'ev', 'av', '! ', 'im', 'et', 'ck', 'fo', 'bu', 'su', 'id', '..', 'ep', 'om', 'el', 'ip', 'if', 'gr', ' (', 'ca', 'ie', 'ho', 'br', 'iz', 'pu', 'sk', 'jo', 'gu', 'sc', 'ph', 'um', 'ty', '? ', 'ss', 'ol', 'bl', 'ps', \"'t\", 'ag', 'aw', 'zz', 'od', 'au', 'af', 'ak', 'cr', 'gy', 'hu', 'tw', 'fl', 'pr', 'ob', 'du', 'sa', 'ds', 'ft', '00', 'ot', 'ok', ') ', 'je', ':\\n', 'os', 'dy', 'ys', '?\\n', 'sm', 'ks', 'na', '20', 'gi', 'la', 'ru', 'kn', 'ls', 'mu', 'ef', 'ry', 'ix', 'ai', ' -', 'sl', 'ue', 'my', 'ms', 'vr', 'ju', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', '\\n', '-', '&', '/', \"'\", '\"', ':', ',', '.', '(', ')', '!', '%', '?', '+']\n"
     ]
    }
   ],
   "source": [
    "del vectorizer\n",
    "del transformed\n",
    "\n",
    "from bpe import BytePairEncoding\n",
    "\n",
    "# Fit the BPE to the dataset and show the longest tokens.\n",
    "enc = BytePairEncoding().fit(data, size=800)\n",
    "t = enc.token_to_text.copy()\n",
    "t.sort(key=len, reverse=True)\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform all the description and rename the columns to be slightly helpful when looking at the data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_a</th>\n",
       "      <th>desc_b</th>\n",
       "      <th>desc_c</th>\n",
       "      <th>desc_d</th>\n",
       "      <th>desc_e</th>\n",
       "      <th>desc_f</th>\n",
       "      <th>desc_g</th>\n",
       "      <th>desc_h</th>\n",
       "      <th>desc_i</th>\n",
       "      <th>desc_j</th>\n",
       "      <th>...</th>\n",
       "      <th>desc_ju</th>\n",
       "      <th>desc_ali</th>\n",
       "      <th>desc_tle</th>\n",
       "      <th>desc_destroy</th>\n",
       "      <th>desc_ground</th>\n",
       "      <th>desc_ouse</th>\n",
       "      <th>desc_fac</th>\n",
       "      <th>desc_learn</th>\n",
       "      <th>desc_search</th>\n",
       "      <th>desc_kill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15039</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15040 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_a  desc_b  desc_c  desc_d  desc_e  desc_f  desc_g  desc_h  desc_i   \n",
       "0           0       1       3       0       0       1       1       0       0  \\\n",
       "1           2       0       0       0       1       1       0       0       0   \n",
       "2           4       0       1       0       1       2       2       0       3   \n",
       "3           3       1       3       2       1       2       0       0       0   \n",
       "4           2       0       0       1       1       2       1       0       1   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15035       5       1       1       0       2       3       2       1       1   \n",
       "15036       1       0       1       0       3       0       0       2       5   \n",
       "15037      17       8       8      10       6      11       8       3       4   \n",
       "15038       4       1       1       1       4       1       1       0       2   \n",
       "15039       3       2       0       0       0       1       0       0       1   \n",
       "\n",
       "       desc_j  ...  desc_ju  desc_ali  desc_tle  desc_destroy  desc_ground   \n",
       "0           0  ...        0         0         0             0            0  \\\n",
       "1           0  ...        0         0         0             0            0   \n",
       "2           0  ...        0         0         0             0            0   \n",
       "3           0  ...        0         0         0             0            0   \n",
       "4           0  ...        0         1         0             0            0   \n",
       "...       ...  ...      ...       ...       ...           ...          ...   \n",
       "15035       0  ...        0         0         0             0            0   \n",
       "15036       0  ...        0         0         0             0            0   \n",
       "15037       2  ...        0         0         0             0            0   \n",
       "15038       0  ...        0         0         0             0            1   \n",
       "15039       0  ...        0         0         0             0            0   \n",
       "\n",
       "       desc_ouse  desc_fac  desc_learn  desc_search  desc_kill  \n",
       "0              0         0           0            0          0  \n",
       "1              0         0           0            0          0  \n",
       "2              0         0           0            0          0  \n",
       "3              0         0           0            0          0  \n",
       "4              0         1           0            1          0  \n",
       "...          ...       ...         ...          ...        ...  \n",
       "15035          1         0           0            0          0  \n",
       "15036          0         0           0            0          0  \n",
       "15037          0         0           1            1          0  \n",
       "15038          0         0           0            0          0  \n",
       "15039          0         0           0            0          0  \n",
       "\n",
       "[15040 rows x 800 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def name(x):\n",
    "    return \"desc_\" + enc.token_to_text[x]\n",
    "\n",
    "count = data.apply(enc.transform_count, axis=1)\n",
    "count = count.rename(name, axis=1)\n",
    "\n",
    "count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will be using the `TfidfTransformer` to normalize the data a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>790</th>\n",
       "      <th>791</th>\n",
       "      <th>792</th>\n",
       "      <th>793</th>\n",
       "      <th>794</th>\n",
       "      <th>795</th>\n",
       "      <th>796</th>\n",
       "      <th>797</th>\n",
       "      <th>798</th>\n",
       "      <th>799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027207</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073114</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083627</td>\n",
       "      <td>0.036027</td>\n",
       "      <td>0.100212</td>\n",
       "      <td>0.067177</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025477</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>0.037155</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>0.010242</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>0.019560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053919</td>\n",
       "      <td>0.143304</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>0.033940</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.024056</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.026656</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>0.01047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>0.031722</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.039371</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.010290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023241</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15039</th>\n",
       "      <td>0.078085</td>\n",
       "      <td>0.067280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038139</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15040 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6     \n",
       "0      0.000000  0.027207  0.075679  0.000000  0.000000  0.025551  0.027315  \\\n",
       "1      0.041318  0.000000  0.000000  0.000000  0.025640  0.025075  0.000000   \n",
       "2      0.066529  0.000000  0.019931  0.000000  0.020643  0.040376  0.043162   \n",
       "3      0.083627  0.036027  0.100212  0.067177  0.034597  0.067669  0.000000   \n",
       "4      0.042289  0.000000  0.000000  0.025477  0.026243  0.051328  0.027436   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15035  0.037155  0.009604  0.008905  0.000000  0.018446  0.027058  0.019284   \n",
       "15036  0.019560  0.000000  0.023439  0.000000  0.072828  0.000000  0.000000   \n",
       "15037  0.033940  0.020642  0.019139  0.024056  0.014867  0.026656  0.020724   \n",
       "15038  0.031722  0.010250  0.009503  0.009556  0.039371  0.009626  0.010290   \n",
       "15039  0.078085  0.067280  0.000000  0.000000  0.000000  0.031592  0.000000   \n",
       "\n",
       "            7         8        9    ...  790       791  792  793       794   \n",
       "0      0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000  \\\n",
       "1      0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2      0.000000  0.073114  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3      0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4      0.000000  0.030983  0.00000  ...  0.0  0.075071  0.0  0.0  0.000000   \n",
       "...         ...       ...      ...  ...  ...       ...  ...  ...       ...   \n",
       "15035  0.010242  0.010889  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "15036  0.053919  0.143304  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "15037  0.008255  0.011702  0.01047  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "15038  0.000000  0.023241  0.00000  ...  0.0  0.000000  0.0  0.0  0.026837   \n",
       "15039  0.000000  0.038139  0.00000  ...  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "            795       796       797       798  799  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "4      0.000000  0.071898  0.000000  0.071020  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "15035  0.026145  0.000000  0.000000  0.000000  0.0  \n",
       "15036  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "15037  0.000000  0.000000  0.006678  0.006706  0.0  \n",
       "15038  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "15039  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "\n",
       "[15040 rows x 800 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_tfidf = pd.DataFrame(TfidfTransformer().fit_transform(count).todense())\n",
    "count_tfidf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally combine all these data with our numerical data to do some regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achievements</th>\n",
       "      <th>average_playtime</th>\n",
       "      <th>median_playtime</th>\n",
       "      <th>owners</th>\n",
       "      <th>price</th>\n",
       "      <th>platforms_windows</th>\n",
       "      <th>platforms_mac</th>\n",
       "      <th>platforms_linux</th>\n",
       "      <th>categories_Multi-player</th>\n",
       "      <th>categories_Online Multi-Player</th>\n",
       "      <th>...</th>\n",
       "      <th>desc_ju</th>\n",
       "      <th>desc_ali</th>\n",
       "      <th>desc_tle</th>\n",
       "      <th>desc_destroy</th>\n",
       "      <th>desc_ground</th>\n",
       "      <th>desc_ouse</th>\n",
       "      <th>desc_fac</th>\n",
       "      <th>desc_learn</th>\n",
       "      <th>desc_search</th>\n",
       "      <th>desc_kill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17612</td>\n",
       "      <td>317</td>\n",
       "      <td>7.176091</td>\n",
       "      <td>7.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>62</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>34</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>184</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "      <td>415</td>\n",
       "      <td>6.875061</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.544068</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15040 rows × 868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       achievements  average_playtime  median_playtime    owners  price   \n",
       "0                 0             17612              317  7.176091   7.19  \\\n",
       "1                 0               277               62  6.875061   3.99   \n",
       "2                 0               187               34  6.875061   3.99   \n",
       "3                 0               258              184  6.875061   3.99   \n",
       "4                 0               624              415  6.875061   3.99   \n",
       "...             ...               ...              ...       ...    ...   \n",
       "15035            12                 0                0  4.000000   7.19   \n",
       "15036             7                 0                0  4.000000   0.00   \n",
       "15037             0                 0                0  4.544068   0.00   \n",
       "15038            23                 0                0  4.000000   6.10   \n",
       "15039             0                 0                0  4.000000   0.79   \n",
       "\n",
       "       platforms_windows  platforms_mac  platforms_linux   \n",
       "0                      1              1                1  \\\n",
       "1                      1              1                1   \n",
       "2                      1              1                1   \n",
       "3                      1              1                1   \n",
       "4                      1              1                1   \n",
       "...                  ...            ...              ...   \n",
       "15035                  1              0                0   \n",
       "15036                  1              0                0   \n",
       "15037                  1              0                0   \n",
       "15038                  1              0                0   \n",
       "15039                  1              0                0   \n",
       "\n",
       "       categories_Multi-player  categories_Online Multi-Player  ...  desc_ju   \n",
       "0                            1                               1  ...      0.0  \\\n",
       "1                            1                               1  ...      0.0   \n",
       "2                            1                               0  ...      0.0   \n",
       "3                            1                               1  ...      0.0   \n",
       "4                            1                               0  ...      0.0   \n",
       "...                        ...                             ...  ...      ...   \n",
       "15035                        0                               0  ...      0.0   \n",
       "15036                        0                               0  ...      0.0   \n",
       "15037                        0                               0  ...      0.0   \n",
       "15038                        0                               0  ...      0.0   \n",
       "15039                        0                               0  ...      0.0   \n",
       "\n",
       "       desc_ali  desc_tle  desc_destroy  desc_ground  desc_ouse  desc_fac   \n",
       "0      0.000000       0.0           0.0     0.000000   0.000000  0.000000  \\\n",
       "1      0.000000       0.0           0.0     0.000000   0.000000  0.000000   \n",
       "2      0.000000       0.0           0.0     0.000000   0.000000  0.000000   \n",
       "3      0.000000       0.0           0.0     0.000000   0.000000  0.000000   \n",
       "4      0.075071       0.0           0.0     0.000000   0.000000  0.071898   \n",
       "...         ...       ...           ...          ...        ...       ...   \n",
       "15035  0.000000       0.0           0.0     0.000000   0.026145  0.000000   \n",
       "15036  0.000000       0.0           0.0     0.000000   0.000000  0.000000   \n",
       "15037  0.000000       0.0           0.0     0.000000   0.000000  0.000000   \n",
       "15038  0.000000       0.0           0.0     0.026837   0.000000  0.000000   \n",
       "15039  0.000000       0.0           0.0     0.000000   0.000000  0.000000   \n",
       "\n",
       "       desc_learn  desc_search  desc_kill  \n",
       "0        0.000000     0.000000        0.0  \n",
       "1        0.000000     0.000000        0.0  \n",
       "2        0.000000     0.000000        0.0  \n",
       "3        0.000000     0.000000        0.0  \n",
       "4        0.000000     0.071020        0.0  \n",
       "...           ...          ...        ...  \n",
       "15035    0.000000     0.000000        0.0  \n",
       "15036    0.000000     0.000000        0.0  \n",
       "15037    0.006678     0.006706        0.0  \n",
       "15038    0.000000     0.000000        0.0  \n",
       "15039    0.000000     0.000000        0.0  \n",
       "\n",
       "[15040 rows x 868 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in = pd.concat([data_num, count_tfidf.rename(name, axis=1)], axis=1)\n",
    "data_in"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get some intuition, let's check the correlation between price and all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc_levels                          -0.108471\n",
       "desc_you                             -0.109229\n",
       "categories_Co-op                      0.111115\n",
       "positive_ratio                        0.112798\n",
       "categories_Steam Achievements         0.116947\n",
       "desc_game                            -0.117270\n",
       "genres_Animation & Modeling           0.120740\n",
       "categories_Multi-player               0.120763\n",
       "desc_ition                            0.122776\n",
       "desc_new                              0.124421\n",
       "categories_Steam Workshop             0.124569\n",
       "genres_Design & Illustration          0.130832\n",
       "categories_Full controller support    0.168108\n",
       "categories_Steam Cloud                0.216740\n",
       "genres_Casual                        -0.237632\n",
       "genres_Indie                         -0.255534\n",
       "genres_Free to Play                  -0.282129\n",
       "price                                 1.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data_in.corr()[\"price\"]\n",
    "corr[corr.abs() > 0.1].sort_values(key=lambda x: abs(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not looking too good :/\n",
    "\n",
    "Let's push on with machine learning regardless but it is likely that testing accuracy will be similar if not lower.\n",
    "Just to keep the runtime saner, we will only be choosing columns that have a (relatively) high correlation.\n",
    "\n",
    "The choice of `0.07` as the threshold is totally arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape: (11280, 52)\n",
      "Test input shape: (3760, 52)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_x = data_in[data_in.columns[corr.abs() > 0.07]].drop(columns=\"price\")\n",
    "data_y = data_in[[\"price\"]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1234567)\n",
    "print(\"Train input shape:\", x_train.shape)\n",
    "print(\"Test input shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dummy Regressor (Baseline) ===\n",
      "Score: -0.00 (p-value 0.714)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Linear Regression ===\n",
      "Score: 0.30 (p-value 0.048)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Decision Tree ===\n",
      "Score: -0.26 (p-value 0.048)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Random Forest ===\n",
      "Score: 0.38 (p-value 0.091)\n",
      "               Best: 0.091\n",
      "\n",
      "=== Boosting Regressor ===\n",
      "Score: 0.39 (p-value 0.167)\n",
      "               Best: 0.167\n",
      "\n",
      "=== Multi-layer Perceptron ===\n",
      "Score: 0.09 (p-value 0.250)\n",
      "               Best: 0.250\n",
      "\n",
      "=== MLP Prev Optimization ===\n",
      "Score: 0.33 (p-value 0.333)\n",
      "               Best: 0.333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "y_train_arr = y_train_scaled.ravel()\n",
    "y_test_arr = y_test_scaled.ravel()\n",
    "\n",
    "print()\n",
    "\n",
    "evaluate(\"Dummy Regressor (Baseline)\", DummyRegressor())\n",
    "evaluate(\"Linear Regression\", LinearRegression())\n",
    "evaluate(\"Decision Tree\", DecisionTreeRegressor(random_state=0))\n",
    "evaluate(\"Random Forest\", RandomForestRegressor(random_state=0, max_samples=0.5), perm=10)\n",
    "evaluate(\"Boosting Regressor\", HistGradientBoostingRegressor(random_state=0), perm=5)\n",
    "\n",
    "# Ignore ConvergenceWarning to avoid spamming the output.\n",
    "# SGD does not converge in this dataset.\n",
    "warnings.filterwarnings(action=\"ignore\", category=ConvergenceWarning)\n",
    "evaluate(\"Multi-layer Perceptron\", MLPRegressor(random_state=0, solver=\"adam\"), perm=3)\n",
    "evaluate(\"MLP Prev Optimization\", MLPRegressor(\n",
    "    random_state=0, activation=\"relu\", solver=\"sgd\", learning_rate=\"constant\", alpha=0.05, hidden_layer_sizes=(50, 50), max_iter=100), perm=2)\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it seems like we have scored lower. This may be caused by the fact that we have a large set of input, causing the models to overfit to the training data.\n",
    "\n",
    "Let's try again with a smaller input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape: (11280, 9)\n",
      "Test input shape: (3760, 9)\n",
      "\n",
      "=== Dummy Regressor (Baseline) ===\n",
      "Score: -0.00 (p-value 0.714)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Linear Regression ===\n",
      "Score: 0.25 (p-value 0.048)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Decision Tree ===\n",
      "Score: -0.04 (p-value 0.048)\n",
      "               Best: 0.048\n",
      "\n",
      "=== Random Forest ===\n",
      "Score: 0.24 (p-value 0.091)\n",
      "               Best: 0.091\n",
      "\n",
      "=== Boosting Regressor ===\n",
      "Score: 0.27 (p-value 0.167)\n",
      "               Best: 0.167\n",
      "\n",
      "=== Multi-layer Perceptron ===\n",
      "Score: 0.30 (p-value 0.250)\n",
      "               Best: 0.250\n",
      "\n",
      "=== MLP Prev Optimization ===\n",
      "Score: 0.30 (p-value 0.333)\n",
      "               Best: 0.333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_x = data_in[data_in.columns[corr.abs() > 0.121]].drop(columns=\"price\")\n",
    "data_y = data_in[[\"price\"]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1234567)\n",
    "print(\"Train input shape:\", x_train.shape)\n",
    "print(\"Test input shape:\", x_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "y_train_arr = y_train_scaled.ravel()\n",
    "y_test_arr = y_test_scaled.ravel()\n",
    "\n",
    "print()\n",
    "\n",
    "evaluate(\"Dummy Regressor (Baseline)\", DummyRegressor())\n",
    "evaluate(\"Linear Regression\", LinearRegression())\n",
    "evaluate(\"Decision Tree\", DecisionTreeRegressor(random_state=0))\n",
    "evaluate(\"Random Forest\", RandomForestRegressor(random_state=0, max_samples=0.5), perm=10)\n",
    "evaluate(\"Boosting Regressor\", HistGradientBoostingRegressor(random_state=0), perm=5)\n",
    "\n",
    "# Ignore ConvergenceWarning to avoid spamming the output.\n",
    "# SGD does not converge in this dataset.\n",
    "warnings.filterwarnings(action=\"ignore\", category=ConvergenceWarning)\n",
    "evaluate(\"Multi-layer Perceptron\", MLPRegressor(random_state=0, solver=\"adam\"), perm=3)\n",
    "evaluate(\"MLP Prev Optimization\", MLPRegressor(\n",
    "    random_state=0, activation=\"relu\", solver=\"sgd\", learning_rate=\"constant\", alpha=0.05, hidden_layer_sizes=(50, 50), max_iter=100), perm=2)\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, that was not strictly the case.\n",
    "\n",
    "While the score of MLP did improve, it still performed worse than the boosting regressor did in the previous run when it had more data.\n",
    "\n",
    "It is likely that MLP did overfit earlier but it did not perform too well in this case either. As such, we will be using Boosting Regressor from this point onwards, tweaking the hyperparameters and hopefully getting a decent score with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initial numerical dataset ===\n",
      "Best parameters were {'learning_rate': 0.05, 'loss': 'squared_error', 'max_iter': 200}\n",
      "Score: 0.47\n",
      "\n",
      "=== Trimmed text dataset ===\n",
      "Best parameters were {'learning_rate': 0.05, 'loss': 'squared_error', 'max_iter': 100}\n",
      "Score: 0.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Back to the 1st and 2nd test set.\n",
    "def try_with(dataset, data_x, data_y):\n",
    "    x_train, _, y_train, _ = train_test_split(data_x, data_y, random_state=1234567)\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "    y_train_arr = y_train_scaled.ravel()\n",
    "    parameter_space = {\n",
    "        \"loss\": [\"squared_error\", \"absolute_error\"],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"max_iter\": [50, 100, 200],\n",
    "    }\n",
    "    hgbr = HistGradientBoostingRegressor(random_state=0)\n",
    "    grid_search = GridSearchCV(hgbr, parameter_space, cv=5)\n",
    "    grid_search.fit(x_train_scaled, y_train_arr)\n",
    "    print(f\"=== {dataset} ===\")\n",
    "    print(f\"Best parameters were {grid_search.best_params_}\")\n",
    "    print(f\"Score: {grid_search.best_score_:.2f}\")\n",
    "    print()\n",
    "    return grid_search\n",
    "\n",
    "data_1_x = data_num.drop(columns=\"price\")\n",
    "data_1_y = data_num[[\"price\"]]\n",
    "data_2_x = data_in[data_in.columns[corr.abs() > 0.07]].drop(columns=\"price\")\n",
    "data_2_y = data_in[[\"price\"]]\n",
    "grid_1 = try_with(\"Initial numerical dataset\", data_1_x, data_1_y)\n",
    "grid_2 = try_with(\"Trimmed text dataset\", data_2_x, data_2_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, the best model (in the scope of this project) was in front of our eyes all along. It's the gradient boosting regressor with half the learning rate and double max iterations to compensate for the halved learning rate.\n",
    "\n",
    "Let's try and run this against our test set which we have been avoiding up until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the final R^2 on the test data set is: 0.46\n"
     ]
    }
   ],
   "source": [
    "_, x_test, _, y_test = train_test_split(data_1_x, data_1_y, random_state=1234567)\n",
    "scaler = StandardScaler()\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "y_scaler = StandardScaler()\n",
    "y_test_scaled = y_scaler.fit_transform(y_test)\n",
    "y_test_arr = y_test_scaled.ravel()\n",
    "print(f\"And the final R^2 on the test data set is: {grid_1.score(x_test_scaled, y_test_arr):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In the end, we went full circle back to the start with the gradient boosting regressor.\n",
    "\n",
    "It is unfortunate but our current approach towards text processing did not correspond to the price but instead only caused noise and lowered the accuracy.\n",
    "\n",
    "With `achievements`, `average_playtime`, `median_playtime`, `owners`, `age`, `positive_ratio`, `genre` and `categories`, we can guess in the ballpark of the price with a slightly below average accuracy as we ignored information on the graphics of the game which likely contributes significantly to the price of a game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
